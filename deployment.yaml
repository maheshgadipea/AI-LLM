apiVersion: apps/v1
kind: Deployment
metadata:
  name: mistral-ai-llm
  namespace: ns1
spec:
  progressDeadlineSeconds: 600
  replicas: 0
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: mistral-ai-llm
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: mistral-ai-llm
    spec:
      containers:
      - env:
        - name: MODEL_PATH
          value: /llmmodels/NLG_FINETUNEDMODELS/DATASET_MODELS/FINETUNED_MISTRALV2_V5/MISTRAL_MERGED_MODEL_JAN30_V3_0021
        image: mosaiccloudacr.azurecr.io/mosaic-ai-logistics/mosaic-notebooks-manager/jupyter/3.8:mistral_ai
        imagePullPolicy: Always
        name: mistral-ai-llm
        livenessProbe:
          exec:
            command:
            - nvidia-smi
          failureThreshold: 3
          initialDelaySeconds: 300
          periodSeconds: 300
          successThreshold: 1
          timeoutSeconds: 60
        ports:
        - containerPort: 8080
          protocol: TCP
        resources:
          limits:
            memory: 32Gi
            nvidia.com/gpu: "1"
          requests:
            memory: 300Mi
            nvidia.com/gpu: "1"
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /llmmodels
          name: llm-pvc
      dnsPolicy: ClusterFirst
      nodeSelector: 
        node.kubernetes.io/instance-type: Standard_NC24ads_A100_v4
      tolerations:
      - effect: NoSchedule
        key: model_type
        operator: Equal
        value: gpu_enabled
      imagePullSecrets:
      - name: gitlab
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
      volumes:
      - name: llm-pvc
        persistentVolumeClaim:
          claimName: llm-pvc
---

### Service.yaml
# service.yaml
apiVersion: v1
kind: Service
metadata:
  name: mistral-ai-llm-service
  namespace: ns1
spec:
  selector:
    app: mistral-ai-llm
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
  type: ClusterIP

---

### Ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    kubernetes.io/ingress.class: nginx
  labels:
    app: mistral-ai-llm
  name: ing-mistral-ai-llm
  namespace: ns1
spec:
  rules:
  - host: refract.fosfor.com
    http:
      paths:
      - backend:
          service:
            name: mistral-ai-llm-service
            port:
              number: 80
        path: /model/generate
        pathType: Prefix

status:
  loadBalancer:
    ingress:
    - ip: 10.30.0.4
    - ip: 10.30.1.100

